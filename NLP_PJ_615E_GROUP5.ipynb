{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NLP_PJ_615E_GROUP5",
      "provenance": [],
      "collapsed_sections": [],
      "toc_visible": true,
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyOFFVE1N+xP182Fnxd86kqV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "cdd3348a271843509d865906f3428b3d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_9912634c2b0649859ece89ef2b5b84a1",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_bb128bbd055447c18675fa6204b9a6f0",
              "IPY_MODEL_140faad008bf41c9ba4e4aaabea0c468"
            ]
          }
        },
        "9912634c2b0649859ece89ef2b5b84a1": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "bb128bbd055447c18675fa6204b9a6f0": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_ed7233f5c5854b8284532e6dbb363e01",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 213450,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 213450,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_e6975e3ae67e4e9f8804507ab8eac078"
          }
        },
        "140faad008bf41c9ba4e4aaabea0c468": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_a72852787f304ad0ae6b724428a3553a",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 213k/213k [00:00&lt;00:00, 367kB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_efe07eca024e49b68417f278561969f4"
          }
        },
        "ed7233f5c5854b8284532e6dbb363e01": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "e6975e3ae67e4e9f8804507ab8eac078": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "a72852787f304ad0ae6b724428a3553a": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "efe07eca024e49b68417f278561969f4": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "e5d334896a9e4048a2570b14a0df4fe8": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_c8ecfbd40edd45d1948b681e37b14954",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_5cb015e1957f4548be4e8f76707afcb3",
              "IPY_MODEL_7988c8797b824820a1842c5c5f9edeac"
            ]
          }
        },
        "c8ecfbd40edd45d1948b681e37b14954": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "5cb015e1957f4548be4e8f76707afcb3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b851193b11bd4d36a0b8e5d5e3e1886f",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 625,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 625,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_a22954bc0e194700b835c6ae0a4ebd9a"
          }
        },
        "7988c8797b824820a1842c5c5f9edeac": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_3ec3c7c90e7447ec94a1ee638ead8c51",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 625/625 [00:02&lt;00:00, 266B/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_8d5be7370e414c9ca64f5579fb7a3995"
          }
        },
        "b851193b11bd4d36a0b8e5d5e3e1886f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "a22954bc0e194700b835c6ae0a4ebd9a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3ec3c7c90e7447ec94a1ee638ead8c51": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "8d5be7370e414c9ca64f5579fb7a3995": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "4799a649d51e4bd69f96f99cb424d947": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_4fa56cf7841f47f2ae75dada06b8f53c",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_9f0c2bfad66648de8d59a71b68c73038",
              "IPY_MODEL_468feedb794f4e55b471e4b19a0e717c"
            ]
          }
        },
        "4fa56cf7841f47f2ae75dada06b8f53c": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "9f0c2bfad66648de8d59a71b68c73038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b0be4be54bf4440abaeb623cfe6a3291",
            "_dom_classes": [],
            "description": "Downloading: 100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 1338740706,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 1338740706,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_1915d893cc8943fa976c343537058647"
          }
        },
        "468feedb794f4e55b471e4b19a0e717c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_d40d5a872f7a4c8d930edd93170f1c7f",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 1.34G/1.34G [00:49&lt;00:00, 26.9MB/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_0aebb875d6314297871762fd51e75a62"
          }
        },
        "b0be4be54bf4440abaeb623cfe6a3291": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "1915d893cc8943fa976c343537058647": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "d40d5a872f7a4c8d930edd93170f1c7f": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "0aebb875d6314297871762fd51e75a62": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/head4ths/NLP/blob/master/NLP_PJ_615E_GROUP5.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_tMHXTl8eeCD",
        "colab_type": "text"
      },
      "source": [
        "# HW 확인\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zZY7oCrMfhV6",
        "colab_type": "text"
      },
      "source": [
        "## GPU 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APT2CZfZeOnl",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 377
        },
        "outputId": "203ac901-2bff-49a0-f8ae-f61d33308b59"
      },
      "source": [
        "gpu_info = !nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if gpu_info.find('failed') >= 0:\n",
        "  print('GPU 할당 필요')\n",
        "else:\n",
        "  print(gpu_info)"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Jun 29 04:11:37 2020       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 450.36.06    Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla P100-PCIE...  Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   47C    P0    29W / 250W |      0MiB / 16280MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3jYWF5VnfodD",
        "colab_type": "text"
      },
      "source": [
        "## 메모리 확인"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vcbl76UcebyD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e4401ef9-57ee-4fbd-e932-7befebc039c5"
      },
      "source": [
        "from psutil import virtual_memory\n",
        "ram_gb = virtual_memory().total / 1e9\n",
        "print('RAM 사이즈 {:.1f} GB'.format(ram_gb))"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RAM 사이즈 27.4 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SSbhxmHTgClz",
        "colab_type": "text"
      },
      "source": [
        "## 기타 사양 확인 "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1zI27Y9wfzjW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "c98878da-52a7-428c-ee6f-139a5816e50f"
      },
      "source": [
        "!cat /etc/issue.net"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Ubuntu 18.04.3 LTS\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SQTNxLyvfzlz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "18f93dba-2bb4-4e14-f552-ce7eb25e6795"
      },
      "source": [
        "!head /proc/cpuinfo"
      ],
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "processor\t: 0\n",
            "vendor_id\t: GenuineIntel\n",
            "cpu family\t: 6\n",
            "model\t\t: 63\n",
            "model name\t: Intel(R) Xeon(R) CPU @ 2.30GHz\n",
            "stepping\t: 0\n",
            "microcode\t: 0x1\n",
            "cpu MHz\t\t: 2300.000\n",
            "cache size\t: 46080 KB\n",
            "physical id\t: 0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hE9CStdjfzoR",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "a82b552d-9193-462b-ba2d-b63d040e78f5"
      },
      "source": [
        "!head -n 3 /proc/meminfo"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MemTotal:       26751700 kB\n",
            "MemFree:        23888956 kB\n",
            "MemAvailable:   25726684 kB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nY4QgbmLfzq4",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 197
        },
        "outputId": "eb79d454-b1da-468d-84e6-858145a85cc7"
      },
      "source": [
        "!df -h"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Filesystem      Size  Used Avail Use% Mounted on\n",
            "overlay          69G   32G   34G  49% /\n",
            "tmpfs            64M     0   64M   0% /dev\n",
            "tmpfs            13G     0   13G   0% /sys/fs/cgroup\n",
            "shm              13G     0   13G   0% /dev/shm\n",
            "/dev/sda1        75G   33G   43G  44% /opt/bin\n",
            "tmpfs            13G   16K   13G   1% /var/colab\n",
            "tmpfs            13G     0   13G   0% /proc/acpi\n",
            "tmpfs            13G     0   13G   0% /proc/scsi\n",
            "tmpfs            13G     0   13G   0% /sys/firmware\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PE7xSgBcfztN",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "e1bfe4e4-a6dc-4141-9847-59495a23fcf2"
      },
      "source": [
        "!python --version"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Python 3.6.9\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gNThMC4mhB6Z",
        "colab_type": "text"
      },
      "source": [
        "# 환경설정"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GnWbIxIXpUeZ",
        "colab_type": "text"
      },
      "source": [
        "## 튜닝용 파라미터"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0C2uoZqzo_zO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "gv_epoch = 3\n",
        "gv_MAX_LEN = 64\n",
        "gv_batch_size = 10  \n",
        "gv_model_nm = 'bert-large-cased'\n",
        "gv_do_lower_case = False\n",
        "gv_lr = 4e-6\n",
        "gv_train_data = \"NLP/friends_train.json\"\n",
        "\n",
        "gv_num_warmup_steps = 0.2\n",
        "gv_eps = 1e-8\n",
        "gv_seed_val = 2019517005\n",
        "gv_random_state = 20200616"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2Vok8EIGhUda",
        "colab_type": "text"
      },
      "source": [
        "## 라이브러리 설치"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MAcYmeFAgvCO",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 629
        },
        "outputId": "971024c7-ba47-4959-f471-11d1929d1141"
      },
      "source": [
        "!pip install transformers"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting transformers\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/48/35/ad2c5b1b8f99feaaf9d7cdadaeef261f098c6e1a6a2935d4d07662a6b780/transformers-2.11.0-py3-none-any.whl (674kB)\n",
            "\r\u001b[K     |▌                               | 10kB 20.5MB/s eta 0:00:01\r\u001b[K     |█                               | 20kB 1.7MB/s eta 0:00:01\r\u001b[K     |█▌                              | 30kB 2.3MB/s eta 0:00:01\r\u001b[K     |██                              | 40kB 2.5MB/s eta 0:00:01\r\u001b[K     |██▍                             | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |███                             | 61kB 2.2MB/s eta 0:00:01\r\u001b[K     |███▍                            | 71kB 2.5MB/s eta 0:00:01\r\u001b[K     |███▉                            | 81kB 2.7MB/s eta 0:00:01\r\u001b[K     |████▍                           | 92kB 2.9MB/s eta 0:00:01\r\u001b[K     |████▉                           | 102kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▍                          | 112kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████▉                          | 122kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▎                         | 133kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 143kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▎                        | 153kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████▊                        | 163kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▎                       | 174kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████▊                       | 184kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▎                      | 194kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████▊                      | 204kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▏                     | 215kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████▊                     | 225kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▏                    | 235kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████▋                    | 245kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▏                   | 256kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████▋                   | 266kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 276kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████▋                  | 286kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████                  | 296kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████▋                 | 307kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████                 | 317kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████▌                | 327kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████                | 337kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████▌               | 348kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 358kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████▌              | 368kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████              | 378kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████▌             | 389kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 399kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 409kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 419kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▍           | 430kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 440kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▍          | 450kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████▉          | 460kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▍         | 471kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 481kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▎        | 491kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████▉        | 501kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▎       | 512kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████▊       | 522kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▎      | 532kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████▊      | 542kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▏     | 552kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▊     | 563kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▏    | 573kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 583kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▏   | 593kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▋   | 604kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▏  | 614kB 2.8MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 624kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████  | 634kB 2.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▋ | 645kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████ | 655kB 2.8MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▋| 665kB 2.8MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 675kB 2.8MB/s \n",
            "\u001b[?25hRequirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.6/dist-packages (from transformers) (2019.12.20)\n",
            "Collecting sentencepiece\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/a4/d0a884c4300004a78cca907a6ff9a5e9fe4f090f5d95ab341c53d28cbc58/sentencepiece-0.1.91-cp36-cp36m-manylinux1_x86_64.whl (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 14.5MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from transformers) (20.4)\n",
            "Collecting sacremoses\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/7d/34/09d19aff26edcc8eb2a01bed8e98f13a1537005d31e95233fd48216eed10/sacremoses-0.0.43.tar.gz (883kB)\n",
            "\u001b[K     |████████████████████████████████| 890kB 20.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: dataclasses; python_version < \"3.7\" in /usr/local/lib/python3.6/dist-packages (from transformers) (0.7)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from transformers) (1.18.5)\n",
            "Collecting tokenizers==0.7.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/14/e5/a26eb4716523808bb0a799fcfdceb6ebf77a18169d9591b2f46a9adb87d9/tokenizers-0.7.0-cp36-cp36m-manylinux1_x86_64.whl (3.8MB)\n",
            "\u001b[K     |████████████████████████████████| 3.8MB 23.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.6/dist-packages (from transformers) (3.0.12)\n",
            "Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.6/dist-packages (from transformers) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from transformers) (2.23.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (1.12.0)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->transformers) (2.4.7)\n",
            "Requirement already satisfied: click in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (7.1.2)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from sacremoses->transformers) (0.15.1)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2.9)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (1.24.3)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (3.0.4)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->transformers) (2020.6.20)\n",
            "Building wheels for collected packages: sacremoses\n",
            "  Building wheel for sacremoses (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for sacremoses: filename=sacremoses-0.0.43-cp36-none-any.whl size=893260 sha256=6b58f24a14b6037d39d93626a355618093689ba4415ce7515c2824698ea5da76\n",
            "  Stored in directory: /root/.cache/pip/wheels/29/3c/fd/7ce5c3f0666dab31a50123635e6fb5e19ceb42ce38d4e58f45\n",
            "Successfully built sacremoses\n",
            "Installing collected packages: sentencepiece, sacremoses, tokenizers, transformers\n",
            "Successfully installed sacremoses-0.0.43 sentencepiece-0.1.91 tokenizers-0.7.0 transformers-2.11.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mHMw3uKnhXmq",
        "colab_type": "text"
      },
      "source": [
        "## 라이브러리 import"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zByN6QHthMWb",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 127
        },
        "outputId": "fd3927ec-ae89-4b6c-ea5d-b43444d8aaec"
      },
      "source": [
        "import tensorflow as tf\n",
        "import torch\n",
        "\n",
        "from transformers import BertTokenizer\n",
        "from transformers import BertForSequenceClassification, AdamW, BertConfig\n",
        "from transformers import get_linear_schedule_with_warmup\n",
        "from torch.utils.data import TensorDataset, DataLoader, RandomSampler, SequentialSampler\n",
        "from keras.preprocessing.sequence import pad_sequences\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import random\n",
        "import time\n",
        "import datetime\n",
        "\n",
        "from google.colab import files\n",
        "from imblearn.over_sampling import RandomOverSampler"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Using TensorFlow backend.\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/externals/six.py:31: FutureWarning: The module is deprecated in version 0.21 and will be removed in version 0.23 since we've dropped support for Python 2.7. Please rely on the official version of six (https://pypi.org/project/six/).\n",
            "  \"(https://pypi.org/project/six/).\", FutureWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/utils/deprecation.py:144: FutureWarning: The sklearn.neighbors.base module is  deprecated in version 0.22 and will be removed in version 0.24. The corresponding classes / functions should instead be imported from sklearn.neighbors. Anything that cannot be imported from sklearn.neighbors is now part of the private API.\n",
            "  warnings.warn(message, FutureWarning)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kVlcBHGFhD0a",
        "colab_type": "text"
      },
      "source": [
        "# 데이터셋 준비"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UEtm7AZRrKb5",
        "colab_type": "text"
      },
      "source": [
        "## raw data 준비 (github 사용시)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OJ4vVYPIrQ2M",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "outputId": "298c009e-dd5e-4cec-a952-c8272589e681"
      },
      "source": [
        "!git clone https://github.com/head4ths/NLP.git"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cloning into 'NLP'...\n",
            "remote: Enumerating objects: 21, done.\u001b[K\n",
            "remote: Counting objects: 100% (21/21), done.\u001b[K\n",
            "remote: Compressing objects: 100% (21/21), done.\u001b[K\n",
            "remote: Total 21 (delta 8), reused 0 (delta 0), pack-reused 0\u001b[K\n",
            "Unpacking objects: 100% (21/21), done.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMPxGm2BrRo2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "7c518414-7b06-493c-e886-49e40fc1b1e7"
      },
      "source": [
        "!ls NLP -la"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "total 6728\n",
            "drwxr-xr-x 3 root root    4096 Jun 29 04:12 .\n",
            "drwxr-xr-x 1 root root    4096 Jun 29 04:12 ..\n",
            "-rw-r--r-- 1 root root  201615 Jun 29 04:12 en_data.csv\n",
            "-rw-r--r-- 1 root root   45048 Jun 29 04:12 en_sample.csv\n",
            "-rw-r--r-- 1 root root 2839207 Jun 29 04:12 friends_all.json\n",
            "-rw-r--r-- 1 root root  229392 Jun 29 04:12 friends_dev.json\n",
            "-rw-r--r-- 1 root root  544341 Jun 29 04:12 friends_test.json\n",
            "-rw-r--r-- 1 root root 2065470 Jun 29 04:12 friends_train.json\n",
            "drwxr-xr-x 8 root root    4096 Jun 29 04:12 .git\n",
            "-rw-r--r-- 1 root root  846591 Jun 29 04:12 ko_data.csv\n",
            "-rw-r--r-- 1 root root   89587 Jun 29 04:12 ko_sample.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qxc2ee75GYvh",
        "colab_type": "text"
      },
      "source": [
        "## JSON to pandas load"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AsqDjRwOhM8p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "f43531a2-6e2e-4e1e-aaa3-9477225ee52a"
      },
      "source": [
        "pd_train = pd.read_json(gv_train_data, encoding=\"utf-8\") \n",
        "pd_test = pd.read_json(\"NLP/friends_test.json\", encoding=\"utf-8\") \n",
        "pd_submit = pd.read_csv(\"NLP/en_data.csv\") \n",
        "\n",
        "print(pd_train.shape)\n",
        "print(pd_test.shape)\n",
        "print(pd_submit.shape)\n",
        "pd_submit[\"emotion\"] = \"neutral\"\n",
        "\n",
        "print(pd_train[0][0])\n",
        "print(pd_test[0][0])\n",
        "print(pd_submit.head())\n",
        "\n",
        "\n"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(720, 24)\n",
            "(200, 24)\n",
            "(3296, 5)\n",
            "{'speaker': 'Chandler', 'utterance': 'also I was the point person on my company\\x92s transition from the KL-5 to GR-6 system.', 'emotion': 'neutral', 'annotation': '4100000'}\n",
            "{'speaker': 'Mark', 'utterance': 'Why do all you\\x92re coffee mugs have numbers on the bottom?', 'emotion': 'surprise', 'annotation': '2000030'}\n",
            "   id  i_dialog  ...                                          utterance  emotion\n",
            "0   0         0  ...                      Alright, whadyou do with him?  neutral\n",
            "1   1         0  ...                                  Oh! You're awake!  neutral\n",
            "2   2         0  ...  Then you gotta come clean with Ma! This is not...  neutral\n",
            "3   3         0  ...                                  Yeah, but this is  neutral\n",
            "4   4         0  ...          I don't wanna hear it! Now go to my room!  neutral\n",
            "\n",
            "[5 rows x 6 columns]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E2lWoAK0aAWt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "d8f3cb48-57dd-4897-96ed-9ffcce957f1d"
      },
      "source": [
        "pd_submit"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>speaker</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Phoebe</td>\n",
              "      <td>Alright, whadyou do with him?</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Monica</td>\n",
              "      <td>Oh! You're awake!</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Joey</td>\n",
              "      <td>Then you gotta come clean with Ma! This is not...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Tribbiani</td>\n",
              "      <td>Yeah, but this is</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Joey</td>\n",
              "      <td>I don't wanna hear it! Now go to my room!</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3291</th>\n",
              "      <td>3291</td>\n",
              "      <td>239</td>\n",
              "      <td>18</td>\n",
              "      <td>Monica</td>\n",
              "      <td>I guess.</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3292</th>\n",
              "      <td>3292</td>\n",
              "      <td>239</td>\n",
              "      <td>19</td>\n",
              "      <td>Chandler</td>\n",
              "      <td>So, shouldn?t we go give her the benefit of th...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3293</th>\n",
              "      <td>3293</td>\n",
              "      <td>239</td>\n",
              "      <td>20</td>\n",
              "      <td>Monica</td>\n",
              "      <td>Fine. I?m just glad I didn?t give her my secre...</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3294</th>\n",
              "      <td>3294</td>\n",
              "      <td>239</td>\n",
              "      <td>21</td>\n",
              "      <td>Chandler</td>\n",
              "      <td>Out of curiosity, what is your secret ingredient?</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3295</th>\n",
              "      <td>3295</td>\n",
              "      <td>239</td>\n",
              "      <td>22</td>\n",
              "      <td>Monica</td>\n",
              "      <td>Yeah!</td>\n",
              "      <td>neutral</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3296 rows × 6 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...  emotion\n",
              "0        0  ...  neutral\n",
              "1        1  ...  neutral\n",
              "2        2  ...  neutral\n",
              "3        3  ...  neutral\n",
              "4        4  ...  neutral\n",
              "...    ...  ...      ...\n",
              "3291  3291  ...  neutral\n",
              "3292  3292  ...  neutral\n",
              "3293  3293  ...  neutral\n",
              "3294  3294  ...  neutral\n",
              "3295  3295  ...  neutral\n",
              "\n",
              "[3296 rows x 6 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ag5SOu0GIBoV",
        "colab_type": "text"
      },
      "source": [
        "## Flatten\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7iYgb2QkJsFa",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def convert_input_data_flat(p_data):\n",
        "\n",
        "  x = len(p_data.columns)\n",
        "  y = len(p_data[0])\n",
        "\n",
        "  print(\"convert_input_data_flat(x,y) : \" + str(x) + \",\" +str(y) )  \n",
        "\n",
        "  pd_xy = pd.DataFrame()\n",
        "\n",
        "  id = 0 \n",
        "  i_utterance = 0\n",
        "\n",
        "  for j in range(y):\n",
        "    i_utterance = 0\n",
        "    pd_x = pd.DataFrame()\n",
        "    for i in range(x):\n",
        "      #print(i)\n",
        "\n",
        "      if p_data.loc[j,i] != None:\n",
        "        pd_x = pd_x.append(pd.DataFrame.from_dict([p_data.loc[j,i]])  )\n",
        "        id += 1\n",
        "        i_utterance += 1\n",
        "\n",
        "    pd_x.insert(0, \"i_dialog\", j, True)\n",
        "    pd_x.insert(1, \"i_utterance\", range(0,i_utterance), True)\n",
        "    pd_x.drop(['annotation'],axis=1,inplace=True)      \n",
        "    pd_xy = pd_xy.append(pd_x)\n",
        "\n",
        "  pd_xy.insert(0, \"id\", range(0,id), True)    \n",
        "  pd_xy.index = pd_xy[\"id\"]\n",
        "\n",
        "  return pd_xy\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DtPNgZl1hNCL",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 107
        },
        "outputId": "a941f2db-d46b-495c-9bb0-a13ecb3b8c15"
      },
      "source": [
        "train = convert_input_data_flat(pd_train)\n",
        "train[\"utterance\"] = train[\"speaker\"] + \" : \" + train[\"utterance\"]\n",
        "train.drop(['speaker'],axis=1,inplace=True)\n",
        "\n",
        "test = convert_input_data_flat(pd_test)\n",
        "test[\"utterance\"] = test[\"speaker\"] + \" : \" + test[\"utterance\"]\n",
        "test.drop(['speaker'],axis=1,inplace=True)\n",
        "\n",
        "submit = pd.DataFrame(pd_submit)\n",
        "submit[\"utterance\"] = submit[\"speaker\"] + \" : \" + submit[\"utterance\"]\n",
        "submit.drop(['speaker'],axis=1,inplace=True)\n",
        "\n",
        "print(train.shape)\n",
        "print(test.shape)\n",
        "print(submit.shape)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "convert_input_data_flat(x,y) : 24,720\n",
            "convert_input_data_flat(x,y) : 24,200\n",
            "(10561, 5)\n",
            "(2764, 5)\n",
            "(3296, 5)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C70PPNmZJItZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "17d123f6-2151-472e-ae04-d77afd6eb6ea"
      },
      "source": [
        "grouped = train.groupby(train['emotion'])\n",
        "grouped.count()"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>utterance</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>anger</th>\n",
              "      <td>513</td>\n",
              "      <td>513</td>\n",
              "      <td>513</td>\n",
              "      <td>513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>disgust</th>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>fear</th>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>joy</th>\n",
              "      <td>1283</td>\n",
              "      <td>1283</td>\n",
              "      <td>1283</td>\n",
              "      <td>1283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>neutral</th>\n",
              "      <td>4752</td>\n",
              "      <td>4752</td>\n",
              "      <td>4752</td>\n",
              "      <td>4752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>non-neutral</th>\n",
              "      <td>2017</td>\n",
              "      <td>2017</td>\n",
              "      <td>2017</td>\n",
              "      <td>2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>sadness</th>\n",
              "      <td>351</td>\n",
              "      <td>351</td>\n",
              "      <td>351</td>\n",
              "      <td>351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>surprise</th>\n",
              "      <td>1220</td>\n",
              "      <td>1220</td>\n",
              "      <td>1220</td>\n",
              "      <td>1220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "               id  i_dialog  i_utterance  utterance\n",
              "emotion                                            \n",
              "anger         513       513          513        513\n",
              "disgust       240       240          240        240\n",
              "fear          185       185          185        185\n",
              "joy          1283      1283         1283       1283\n",
              "neutral      4752      4752         4752       4752\n",
              "non-neutral  2017      2017         2017       2017\n",
              "sadness       351       351          351        351\n",
              "surprise     1220      1220         1220       1220"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SJQa3tom_03O",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "num_labels = {\n",
        "    \"anger\": 0,\n",
        "    \"disgust\": 1,\n",
        "    \"fear\": 2,\n",
        "    \"joy\": 3,\n",
        "    \"neutral\": 4,\n",
        "    \"non-neutral\": 5,\n",
        "    \"sadness\": 6,\n",
        "    \"surprise\": 7\n",
        "}\n",
        "\n",
        "labels_num = {\n",
        "    0 : \"anger\",\n",
        "    1 : \"disgust\",\n",
        "    2 : \"fear\",\n",
        "    3 : \"joy\",\n",
        "    4 : \"neutral\",\n",
        "    5 : \"non-neutral\",\n",
        "    6 : \"sadness\",\n",
        "    7 : \"surprise\"\n",
        "}\n"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JMir3bfiDRA-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train['emotion'] = train['emotion'].replace(num_labels)\n",
        "test['emotion'] = test['emotion'].replace(num_labels)\n",
        "submit['emotion'] = submit['emotion'].replace(num_labels)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5TUnLLnUElIq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "c5102258-1031-45ac-fd81-ce0042c86ce3"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Chandler : also I was the point person on my c...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>The Interviewer : You mustve had your hands f...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Chandler : That I did. That I did.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>The Interviewer : So lets talk a little bit a...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Chandler : My duties?  All right.</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  i_dialog  ...                                          utterance emotion\n",
              "id                ...                                                           \n",
              "0    0         0  ...  Chandler : also I was the point person on my c...       4\n",
              "1    1         0  ...  The Interviewer : You mustve had your hands f...       4\n",
              "2    2         0  ...                 Chandler : That I did. That I did.       4\n",
              "3    3         0  ...  The Interviewer : So lets talk a little bit a...       4\n",
              "4    4         0  ...                  Chandler : My duties?  All right.       7\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7dyHiu9D_yD9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "1a4c0d2a-401d-4d6d-b872-4dea50c55015"
      },
      "source": [
        "test.head()"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Mark : Why do all youre coffee mugs have numb...</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Rachel : Oh. Thats so Monica can keep track. ...</td>\n",
              "      <td>5</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Rachel : Y'know what?</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Ross : It didnt.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Frank : Okay, so what you used to have with Ra...</td>\n",
              "      <td>3</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  i_dialog  ...                                          utterance emotion\n",
              "id                ...                                                           \n",
              "0    0         0  ...  Mark : Why do all youre coffee mugs have numb...       7\n",
              "1    1         0  ...  Rachel : Oh. Thats so Monica can keep track. ...       5\n",
              "2    2         0  ...                              Rachel : Y'know what?       4\n",
              "3    3         0  ...                                  Ross : It didnt.       4\n",
              "4    4         0  ...  Frank : Okay, so what you used to have with Ra...       3\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hQQZ9ZihH_sH",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "0981a07f-73a0-4863-8bd2-00db582d3764"
      },
      "source": [
        "submit.head()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Phoebe : Alright, whadyou do with him?</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Monica : Oh! You're awake!</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Joey : Then you gotta come clean with Ma! This...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Tribbiani : Yeah, but this is</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Joey : I don't wanna hear it! Now go to my room!</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "   id  i_dialog  ...                                          utterance emotion\n",
              "0   0         0  ...             Phoebe : Alright, whadyou do with him?       4\n",
              "1   1         0  ...                         Monica : Oh! You're awake!       4\n",
              "2   2         0  ...  Joey : Then you gotta come clean with Ma! This...       4\n",
              "3   3         0  ...                  Mr. Tribbiani : Yeah, but this is       4\n",
              "4   4         0  ...   Joey : I don't wanna hear it! Now go to my room!       4\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5nSvsVBWjR-M",
        "colab_type": "text"
      },
      "source": [
        "## Oversampleing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "REHs6FPrleVt",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "5d32852a-92a9-4831-abf1-b69d7b2c432a"
      },
      "source": [
        "\"\"\"\n",
        "ros = RandomOverSampler(random_state=42) \n",
        "\n",
        "print(train.shape)\n",
        "\n",
        "train_tmp = train.copy()\n",
        "oversampled_data, oversampled_label = ros.fit_resample(train_tmp,train_tmp[\"emotion\"])\n",
        "train = pd.DataFrame(oversampled_data, columns=train_tmp.columns) \n",
        "print(train.shape)\n",
        "\"\"\""
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic": {
              "type": "string"
            },
            "text/plain": [
              "'\\nros = RandomOverSampler(random_state=42) \\n\\nprint(train.shape)\\n\\ntrain_tmp = train.copy()\\noversampled_data, oversampled_label = ros.fit_resample(train_tmp,train_tmp[\"emotion\"])\\ntrain = pd.DataFrame(oversampled_data, columns=train_tmp.columns) \\nprint(train.shape)\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3qot1fwWlxs_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "outputId": "485cc506-e627-4d74-8add-2ab2400fb70f"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>id</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Chandler : also I was the point person on my c...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>The Interviewer : You mustve had your hands f...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Chandler : That I did. That I did.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>The Interviewer : So lets talk a little bit a...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Chandler : My duties?  All right.</td>\n",
              "      <td>7</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    id  i_dialog  ...                                          utterance emotion\n",
              "id                ...                                                           \n",
              "0    0         0  ...  Chandler : also I was the point person on my c...       4\n",
              "1    1         0  ...  The Interviewer : You mustve had your hands f...       4\n",
              "2    2         0  ...                 Chandler : That I did. That I did.       4\n",
              "3    3         0  ...  The Interviewer : So lets talk a little bit a...       4\n",
              "4    4         0  ...                  Chandler : My duties?  All right.       7\n",
              "\n",
              "[5 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5syoaS6fw6YD",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 251
        },
        "outputId": "b54d8624-e28e-47a1-8336-d94357958b89"
      },
      "source": [
        "train['emotion'] = train['emotion'].astype('int64')\n",
        "train['emotion']"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "0        4\n",
              "1        4\n",
              "2        4\n",
              "3        4\n",
              "4        7\n",
              "        ..\n",
              "10556    4\n",
              "10557    5\n",
              "10558    7\n",
              "10559    4\n",
              "10560    5\n",
              "Name: emotion, Length: 10561, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "M3Fq9h1Mot6P",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 328
        },
        "outputId": "ee7b91e2-ca30-4813-8e9d-990321dda30d"
      },
      "source": [
        "grouped = train.groupby(train['emotion'])\n",
        "grouped.count()"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>emotion</th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "      <th></th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>513</td>\n",
              "      <td>513</td>\n",
              "      <td>513</td>\n",
              "      <td>513</td>\n",
              "      <td>513</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1283</td>\n",
              "      <td>1283</td>\n",
              "      <td>1283</td>\n",
              "      <td>1283</td>\n",
              "      <td>1283</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4752</td>\n",
              "      <td>4752</td>\n",
              "      <td>4752</td>\n",
              "      <td>4752</td>\n",
              "      <td>4752</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>2017</td>\n",
              "      <td>2017</td>\n",
              "      <td>2017</td>\n",
              "      <td>2017</td>\n",
              "      <td>2017</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>351</td>\n",
              "      <td>351</td>\n",
              "      <td>351</td>\n",
              "      <td>351</td>\n",
              "      <td>351</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>1220</td>\n",
              "      <td>1220</td>\n",
              "      <td>1220</td>\n",
              "      <td>1220</td>\n",
              "      <td>1220</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "           id  i_dialog  i_utterance  utterance  emotion\n",
              "emotion                                                 \n",
              "0         513       513          513        513      513\n",
              "1         240       240          240        240      240\n",
              "2         185       185          185        185      185\n",
              "3        1283      1283         1283       1283     1283\n",
              "4        4752      4752         4752       4752     4752\n",
              "5        2017      2017         2017       2017     2017\n",
              "6         351       351          351        351      351\n",
              "7        1220      1220         1220       1220     1220"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q2PlgbUDpTRy",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "00015727-e8ac-41cd-ea4a-65ffe25ad5cd"
      },
      "source": [
        "print(type(train['emotion']))\n",
        "print(type(test['emotion']))\n",
        "print(type(submit['emotion']))"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n",
            "<class 'pandas.core.series.Series'>\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "32ixnElThGKz",
        "colab_type": "text"
      },
      "source": [
        "# 전처리 - Traning Set "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mNEmVis2j58c",
        "colab_type": "text"
      },
      "source": [
        "## 형식 변환 [CLS] [SEP]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0Vgz7V_BgvE5",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "247bddd9-c8ce-4af2-d053-232a1cc48450"
      },
      "source": [
        "sentences = train['utterance']\n",
        "sentences[:10]"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "0    Chandler : also I was the point person on my c...\n",
              "1    The Interviewer : You mustve had your hands f...\n",
              "2                   Chandler : That I did. That I did.\n",
              "3    The Interviewer : So lets talk a little bit a...\n",
              "4                    Chandler : My duties?  All right.\n",
              "5    The Interviewer : Now youll be heading a whol...\n",
              "6                                    Chandler : I see.\n",
              "7    The Interviewer : But therell be perhaps 30 p...\n",
              "8                             Chandler : Good to know.\n",
              "9              The Interviewer : We can go into detail\n",
              "Name: utterance, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WPN35yRuDBLY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_temp = sentences.copy()\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  if (i == 0 ): \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] [None] [SEP]\" \n",
        "  elif (train['i_dialog'][i-1] !=  train['i_dialog'][i]):  \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] [None] [SEP]\" \n",
        "  else:    \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] \" + str(sentences[i-1]) + \" [SEP]\"\n",
        "\n",
        "sentences = sentences_temp"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6-Sw1ChcgvHv",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "0195e811-12ef-408a-d51f-11757250a598"
      },
      "source": [
        "sentences[:10]"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "0    [CLS] Chandler : also I was the point person o...\n",
              "1    [CLS] The Interviewer : You mustve had your h...\n",
              "2    [CLS] Chandler : That I did. That I did. [SEP]...\n",
              "3    [CLS] The Interviewer : So lets talk a little...\n",
              "4    [CLS] Chandler : My duties?  All right. [SEP] ...\n",
              "5    [CLS] The Interviewer : Now youll be heading ...\n",
              "6    [CLS] Chandler : I see. [SEP] The Interviewer ...\n",
              "7    [CLS] The Interviewer : But therell be perhap...\n",
              "8    [CLS] Chandler : Good to know. [SEP] The Inter...\n",
              "9    [CLS] The Interviewer : We can go into detail ...\n",
              "Name: utterance, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "59myVLdyfz2v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "29ab278d-4c8d-4f38-b97d-55bda894b23d"
      },
      "source": [
        "labels = train[\"emotion\"].values\n",
        "labels"
      ],
      "execution_count": 31,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 7, 4, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 31
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mu3358-okHKl",
        "colab_type": "text"
      },
      "source": [
        "## BERT 토크나이징"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TtHzODp4fz49",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 123,
          "referenced_widgets": [
            "cdd3348a271843509d865906f3428b3d",
            "9912634c2b0649859ece89ef2b5b84a1",
            "bb128bbd055447c18675fa6204b9a6f0",
            "140faad008bf41c9ba4e4aaabea0c468",
            "ed7233f5c5854b8284532e6dbb363e01",
            "e6975e3ae67e4e9f8804507ab8eac078",
            "a72852787f304ad0ae6b724428a3553a",
            "efe07eca024e49b68417f278561969f4"
          ]
        },
        "outputId": "fc770705-cc9b-47b3-ad0b-5502ad8dd2e9"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(gv_model_nm, do_lower_case=gv_do_lower_case)  \n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cdd3348a271843509d865906f3428b3d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=213450.0, style=ProgressStyle(descripti…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n",
            "[CLS] Chandler : also I was the point person on my companys transition from the KL-5 to GR-6 system. [SEP] [None] [SEP]\n",
            "['[CLS]', 'Chandler', ':', 'also', 'I', 'was', 'the', 'point', 'person', 'on', 'my', 'company', '##s', 'transition', 'from', 'the', 'K', '##L', '-', '5', 'to', 'G', '##R', '-', '6', 'system', '.', '[SEP]', '[', 'None', ']', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7eMUbQWLfz7j",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "f77f2037-7627-48a1-f968-a1201f6d0ab4"
      },
      "source": [
        "MAX_LEN = gv_MAX_LEN\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "input_ids[0]"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101, 14394,   131,  1145,   146,  1108,  1103,  1553,  1825,\n",
              "        1113,  1139,  1419,  1116,  6468,  1121,  1103,   148,  2162,\n",
              "         118,   126,  1106,   144,  2069,   118,   127,  1449,   119,\n",
              "         102,   164,  7330,   166,   102,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pwuio3fTkMkr",
        "colab_type": "text"
      },
      "source": [
        "## 어텐션 마스크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "676nig_Efz_2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "4ab6d5bd-a8c6-4f08-949f-655ce44d111f"
      },
      "source": [
        "attention_masks = []\n",
        "\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dsO8GkWhLNpW",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_inputs, validation_inputs, train_labels, validation_labels = train_test_split(input_ids,\n",
        "                                                                                    labels, \n",
        "                                                                                    random_state=gv_random_state, \n",
        "                                                                                    test_size=0.1)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PcvQm0o-LPR3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_masks, validation_masks, _, _ = train_test_split(attention_masks, \n",
        "                                                       input_ids,\n",
        "                                                       random_state=gv_random_state, \n",
        "                                                       test_size=0.1)"
      ],
      "execution_count": 36,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W7U9VP66f0CV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 431
        },
        "outputId": "af23d8ae-e49d-4b8c-9549-2c98cad2011a"
      },
      "source": [
        "train_inputs = torch.tensor(train_inputs)\n",
        "train_labels = torch.tensor(train_labels) \n",
        "train_masks = torch.tensor(train_masks)\n",
        "validation_inputs = torch.tensor(validation_inputs)\n",
        "validation_labels = torch.tensor(validation_labels) \n",
        "validation_masks = torch.tensor(validation_masks)\t\t\t\t\n",
        "\n",
        "print(train_inputs[0])\n",
        "print(train_labels[0])\n",
        "print(train_masks[0])\n",
        "print(validation_inputs[0])\n",
        "print(validation_labels[0])\n",
        "print(validation_masks[0])"
      ],
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([ 101, 9300,  131, 1398, 1268,  117,  146,  112, 1325, 1267, 1128, 1107,\n",
            "        1103, 2106,  119,  102, 8958,  131,  146, 1221,  119,  102,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
            "           0,    0,    0,    0])\n",
            "tensor(4)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n",
            "tensor([  101, 19704,   131,  7066,   118,  5871,   106,  6466, 11012,  1183,\n",
            "          106,   102,  9300,   131,  1573,   146,  1169,  1202,  1122,   136,\n",
            "          102,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "tensor(3)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Fg-ZaxlzkUn1",
        "colab_type": "text"
      },
      "source": [
        "## 배치 사이즈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OaWxb0V1f0E3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = gv_batch_size\n",
        "\n",
        "train_data = TensorDataset(train_inputs, train_masks, train_labels)\n",
        "train_sampler = RandomSampler(train_data)\n",
        "train_dataloader = DataLoader(train_data, sampler=train_sampler, batch_size=batch_size)\n",
        "\n",
        "validation_data = TensorDataset(validation_inputs, validation_masks, validation_labels)\n",
        "validation_sampler = SequentialSampler(validation_data)\n",
        "validation_dataloader = DataLoader(validation_data, sampler=validation_sampler, batch_size=batch_size)"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "agRB5BZvkfO8",
        "colab_type": "text"
      },
      "source": [
        "# 전처리 - Test Set "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_ZROw439kjDN",
        "colab_type": "text"
      },
      "source": [
        "## 형식 변환 [CLS] [SEP]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4hOveQC4f0Hj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "7da96ef8-bfe6-4e55-e232-11d2edca62f5"
      },
      "source": [
        "sentences = test['utterance']\n",
        "sentences[:10]"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "0    Mark : Why do all youre coffee mugs have numb...\n",
              "1    Rachel : Oh. Thats so Monica can keep track. ...\n",
              "2                                Rachel : Y'know what?\n",
              "3                                    Ross : It didnt.\n",
              "4    Frank : Okay, so what you used to have with Ra...\n",
              "5              Joey : Now, wh-what, what is that like?\n",
              "6    Frank : Its so cool man, its so, its just ...\n",
              "7                                   Ross : Yeah, yeah.\n",
              "8                        Joey : Why cant I find that?\n",
              "9         Ross : Dont ask me, I had it and I blew it!\n",
              "Name: utterance, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 39
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ubq1rl6eMZ4x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_temp = sentences.copy()\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  if (i == 0 ): \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] [None] [SEP]\" \n",
        "  elif (test['i_dialog'][i-1] !=  test['i_dialog'][i]):  \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] [None] [SEP]\" \n",
        "  else:    \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] \" + str(sentences[i-1]) + \" [SEP]\"\n",
        "\n",
        "sentences = sentences_temp"
      ],
      "execution_count": 40,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Qsw89B05f0J7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "2f431c85-7232-46f2-89cf-722c06666c39"
      },
      "source": [
        "sentences[:10]"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "id\n",
              "0    [CLS] Mark : Why do all youre coffee mugs hav...\n",
              "1    [CLS] Rachel : Oh. Thats so Monica can keep t...\n",
              "2    [CLS] Rachel : Y'know what? [SEP] Rachel : Oh....\n",
              "3    [CLS] Ross : It didnt. [SEP] Rachel : Y'know ...\n",
              "4    [CLS] Frank : Okay, so what you used to have w...\n",
              "5    [CLS] Joey : Now, wh-what, what is that like? ...\n",
              "6    [CLS] Frank : Its so cool man, its so, its ...\n",
              "7    [CLS] Ross : Yeah, yeah. [SEP] Frank : Its so...\n",
              "8    [CLS] Joey : Why cant I find that? [SEP] Ross...\n",
              "9    [CLS] Ross : Dont ask me, I had it and I blew...\n",
              "Name: utterance, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SnQMjIcRfz9y",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "844fc262-ab83-419a-90a2-da5c6249ce9d"
      },
      "source": [
        "labels = test[\"emotion\"].values\n",
        "labels "
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([7, 5, 4, ..., 4, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 42
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mPpuvv_MtQM4",
        "colab_type": "text"
      },
      "source": [
        "## BERT 토크나이징"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W46Y2eMMfzvZ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "9308fc79-670a-4e16-ec51-8ad78672cbaf"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(gv_model_nm, do_lower_case=gv_do_lower_case)  \n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] Mark : Why do all youre coffee mugs have numbers on the bottom? [SEP] [None] [SEP]\n",
            "['[CLS]', 'Mark', ':', 'Why', 'do', 'all', 'your', '##e', 'coffee', 'mug', '##s', 'have', 'numbers', 'on', 'the', 'bottom', '?', '[SEP]', '[', 'None', ']', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "w0VbOBg_ibUr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "6f4e0667-78e3-4e11-ba2f-9aab2b837f50"
      },
      "source": [
        "MAX_LEN = gv_MAX_LEN\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "input_ids[0]"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101,  2392,   131,  2009,  1202,  1155,  1240,  1162,  3538,\n",
              "       15761,  1116,  1138,  2849,  1113,  1103,  3248,   136,   102,\n",
              "         164,  7330,   166,   102,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XF5qyeEJtTTq",
        "colab_type": "text"
      },
      "source": [
        "## 어텐션 마스크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-EOFkQRqibaI",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "34459922-e5de-421d-edc8-d64798c4be58"
      },
      "source": [
        "attention_masks = []\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p8ZEyAZWibdB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "ad46f4b3-e71e-4ff4-91fc-f862afdb5c35"
      },
      "source": [
        "test_inputs = torch.tensor(input_ids)\n",
        "test_labels = torch.tensor(labels)\n",
        "test_masks = torch.tensor(attention_masks)\n",
        "\n",
        "print(test_inputs[0])\n",
        "print(test_labels[0])\n",
        "print(test_masks[0])"
      ],
      "execution_count": 46,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  101,  2392,   131,  2009,  1202,  1155,  1240,  1162,  3538, 15761,\n",
            "         1116,  1138,  2849,  1113,  1103,  3248,   136,   102,   164,  7330,\n",
            "          166,   102,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "tensor(7)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1.,\n",
            "        1., 1., 1., 1., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jnDfsAgbtW2q",
        "colab_type": "text"
      },
      "source": [
        "## 배치 사이즈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OeIpKZkibgM",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = gv_batch_size\n",
        "test_data = TensorDataset(test_inputs, test_masks, test_labels)\n",
        "test_sampler = RandomSampler(test_data)\n",
        "test_dataloader = DataLoader(test_data, sampler=test_sampler, batch_size=batch_size)"
      ],
      "execution_count": 47,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "O_iWrCGOFIkZ",
        "colab_type": "text"
      },
      "source": [
        "# 전처리 - Submit Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKHUc33mFPgd",
        "colab_type": "text"
      },
      "source": [
        "## 형식 변환 [CLS][SEP]"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "aYWyLMG3k1I6",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 419
        },
        "outputId": "a3a0ae33-e572-47d0-ed37-932cd36e9862"
      },
      "source": [
        "submit"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>id</th>\n",
              "      <th>i_dialog</th>\n",
              "      <th>i_utterance</th>\n",
              "      <th>utterance</th>\n",
              "      <th>emotion</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>Phoebe : Alright, whadyou do with him?</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>Monica : Oh! You're awake!</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>0</td>\n",
              "      <td>2</td>\n",
              "      <td>Joey : Then you gotta come clean with Ma! This...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>0</td>\n",
              "      <td>3</td>\n",
              "      <td>Mr. Tribbiani : Yeah, but this is</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>0</td>\n",
              "      <td>4</td>\n",
              "      <td>Joey : I don't wanna hear it! Now go to my room!</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3291</th>\n",
              "      <td>3291</td>\n",
              "      <td>239</td>\n",
              "      <td>18</td>\n",
              "      <td>Monica : I guess.</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3292</th>\n",
              "      <td>3292</td>\n",
              "      <td>239</td>\n",
              "      <td>19</td>\n",
              "      <td>Chandler : So, shouldn?t we go give her the be...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3293</th>\n",
              "      <td>3293</td>\n",
              "      <td>239</td>\n",
              "      <td>20</td>\n",
              "      <td>Monica : Fine. I?m just glad I didn?t give her...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3294</th>\n",
              "      <td>3294</td>\n",
              "      <td>239</td>\n",
              "      <td>21</td>\n",
              "      <td>Chandler : Out of curiosity, what is your secr...</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3295</th>\n",
              "      <td>3295</td>\n",
              "      <td>239</td>\n",
              "      <td>22</td>\n",
              "      <td>Monica : Yeah!</td>\n",
              "      <td>4</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>3296 rows × 5 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "        id  ...  emotion\n",
              "0        0  ...        4\n",
              "1        1  ...        4\n",
              "2        2  ...        4\n",
              "3        3  ...        4\n",
              "4        4  ...        4\n",
              "...    ...  ...      ...\n",
              "3291  3291  ...        4\n",
              "3292  3292  ...        4\n",
              "3293  3293  ...        4\n",
              "3294  3294  ...        4\n",
              "3295  3295  ...        4\n",
              "\n",
              "[3296 rows x 5 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ampEXhPJFynx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "176f7ae4-7933-4ace-f1b2-0ab51d7bf972"
      },
      "source": [
        "sentences = submit['utterance']\n",
        "sentences[:10]"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0               Phoebe : Alright, whadyou do with him?\n",
              "1                           Monica : Oh! You're awake!\n",
              "2    Joey : Then you gotta come clean with Ma! This...\n",
              "3                    Mr. Tribbiani : Yeah, but this is\n",
              "4     Joey : I don't wanna hear it! Now go to my room!\n",
              "5    Chandler : I don?t want him to tell this story...\n",
              "6    Ross : Oh, but he will. He still tells the sto...\n",
              "7                          Monica : I wasn?t escaping.\n",
              "8    Ross : Then how did you get caught in the barb...\n",
              "9        Monica : I was trying to help out a squirrel.\n",
              "Name: utterance, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VxCxWo5ZMeb2",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sentences_temp = sentences.copy()\n",
        "\n",
        "for i in range(len(sentences)):\n",
        "  if (i == 0 ): \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] [None] [SEP]\" \n",
        "  elif (submit['i_dialog'][i-1] !=  submit['i_dialog'][i]):  \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] [None] [SEP]\" \n",
        "  else:    \n",
        "    sentences_temp[i] = \"[CLS] \" + str(sentences[i]) + \" [SEP] \" + str(sentences[i-1]) + \" [SEP]\"\n",
        "\n",
        "sentences = sentences_temp"
      ],
      "execution_count": 50,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GFZoHukRFzG2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 215
        },
        "outputId": "958a2a1f-6dc0-4b6b-d6e7-3436cc0ebf92"
      },
      "source": [
        "sentences[:10]"
      ],
      "execution_count": 51,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    [CLS] Phoebe : Alright, whadyou do with him? [...\n",
              "1    [CLS] Monica : Oh! You're awake! [SEP] Phoebe ...\n",
              "2    [CLS] Joey : Then you gotta come clean with Ma...\n",
              "3    [CLS] Mr. Tribbiani : Yeah, but this is [SEP] ...\n",
              "4    [CLS] Joey : I don't wanna hear it! Now go to ...\n",
              "5    [CLS] Chandler : I don?t want him to tell this...\n",
              "6    [CLS] Ross : Oh, but he will. He still tells t...\n",
              "7    [CLS] Monica : I wasn?t escaping. [SEP] Ross :...\n",
              "8    [CLS] Ross : Then how did you get caught in th...\n",
              "9    [CLS] Monica : I was trying to help out a squi...\n",
              "Name: utterance, dtype: object"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2v-VanXHF0DP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "2d1e4a0f-c81b-4f2f-d036-f3358253c178"
      },
      "source": [
        "labels = submit[\"emotion\"].values\n",
        "labels "
      ],
      "execution_count": 52,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([4, 4, 4, ..., 4, 4, 4])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wuhfw9ZjFbSx",
        "colab_type": "text"
      },
      "source": [
        "## BERT 토크나이징\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V6Ftr2GTF0Bx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "3c76155c-4e80-4f89-99e4-864eb6fa0d9c"
      },
      "source": [
        "tokenizer = BertTokenizer.from_pretrained(gv_model_nm, do_lower_case=gv_do_lower_case)  \n",
        "tokenized_texts = [tokenizer.tokenize(sent) for sent in sentences]\n",
        "\n",
        "print (sentences[0])\n",
        "print (tokenized_texts[0])"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[CLS] Phoebe : Alright, whadyou do with him? [SEP] [None] [SEP]\n",
            "['[CLS]', 'Phoebe', ':', 'Alright', ',', 'w', '##hady', '##ou', 'do', 'with', 'him', '?', '[SEP]', '[', 'None', ']', '[SEP]']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f8GTUWYlFz7B",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 161
        },
        "outputId": "bc0d4f48-3198-4595-fa20-906da579dcd2"
      },
      "source": [
        "MAX_LEN = gv_MAX_LEN\n",
        "input_ids = [tokenizer.convert_tokens_to_ids(x) for x in tokenized_texts]\n",
        "input_ids = pad_sequences(input_ids, maxlen=MAX_LEN, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
        "input_ids[0]"
      ],
      "execution_count": 54,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([  101, 19704,   131, 18009,   117,   192, 24905,  6094,  1202,\n",
              "        1114,  1140,   136,   102,   164,  7330,   166,   102,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
              "           0])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 54
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dzz_9PZ3Ffvo",
        "colab_type": "text"
      },
      "source": [
        "## 어텐션 마스크"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CsdZ_PczFz5N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "944c8929-ea19-4d04-91f7-48e9b8e599ae"
      },
      "source": [
        "attention_masks = []\n",
        "\n",
        "for seq in input_ids:\n",
        "    seq_mask = [float(i>0) for i in seq]\n",
        "    attention_masks.append(seq_mask)\n",
        "\n",
        "print(attention_masks[0])"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C6lUkjSOF8gJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 233
        },
        "outputId": "90d417e4-26f8-4061-c41b-7d3cc76ceca8"
      },
      "source": [
        "submit_inputs = torch.tensor(input_ids)\n",
        "submit_labels = torch.tensor(labels)\n",
        "submit_masks = torch.tensor(attention_masks)\n",
        "\n",
        "print(submit_inputs[0])\n",
        "print(submit_labels[0])\n",
        "print(submit_masks[0])"
      ],
      "execution_count": 56,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "tensor([  101, 19704,   131, 18009,   117,   192, 24905,  6094,  1202,  1114,\n",
            "         1140,   136,   102,   164,  7330,   166,   102,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0,     0,     0,     0,     0,     0,     0,\n",
            "            0,     0,     0,     0])\n",
            "tensor(4)\n",
            "tensor([1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 1., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
            "        0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WShxP-Z3FiSF",
        "colab_type": "text"
      },
      "source": [
        "## 배치 사이즈"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "U1V0fbPjF8eC",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "batch_size = gv_batch_size\n",
        "submit_data = TensorDataset(submit_inputs, submit_masks, submit_labels)\n",
        "submit_sampler = SequentialSampler(submit_data)\n",
        "submit_dataloader = DataLoader(submit_data, sampler=submit_sampler, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 57,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N-sQsq1stai0",
        "colab_type": "text"
      },
      "source": [
        "# 모델 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bDAje94auua4",
        "colab_type": "text"
      },
      "source": [
        "## 사전 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tuYr4hP_ibYc",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "1689c6e6-4b6d-4e25-d281-cd7c911959fb"
      },
      "source": [
        "device_name = tf.test.gpu_device_name()\n",
        "\n",
        "if device_name == '/device:GPU:0':\n",
        "    print('Found GPU at: {}'.format(device_name))\n",
        "else:\n",
        "    raise SystemError('GPU device not found')"
      ],
      "execution_count": 58,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Found GPU at: /device:GPU:0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dYO3GFYKijix",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 53
        },
        "outputId": "7f998ed7-41bb-43e7-8e00-4fadc4d7b7cf"
      },
      "source": [
        "if torch.cuda.is_available():    \n",
        "    device = torch.device(\"cuda\")\n",
        "    print('There are %d GPU(s) available.' % torch.cuda.device_count())\n",
        "    print('We will use the GPU:', torch.cuda.get_device_name(0))\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print('No GPU available, using the CPU instead.')"
      ],
      "execution_count": 59,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "There are 1 GPU(s) available.\n",
            "We will use the GPU: Tesla P100-PCIE-16GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHSjtPBGvA0u",
        "colab_type": "text"
      },
      "source": [
        "## 모델 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVjA7N3AijoG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "e5d334896a9e4048a2570b14a0df4fe8",
            "c8ecfbd40edd45d1948b681e37b14954",
            "5cb015e1957f4548be4e8f76707afcb3",
            "7988c8797b824820a1842c5c5f9edeac",
            "b851193b11bd4d36a0b8e5d5e3e1886f",
            "a22954bc0e194700b835c6ae0a4ebd9a",
            "3ec3c7c90e7447ec94a1ee638ead8c51",
            "8d5be7370e414c9ca64f5579fb7a3995",
            "4799a649d51e4bd69f96f99cb424d947",
            "4fa56cf7841f47f2ae75dada06b8f53c",
            "9f0c2bfad66648de8d59a71b68c73038",
            "468feedb794f4e55b471e4b19a0e717c",
            "b0be4be54bf4440abaeb623cfe6a3291",
            "1915d893cc8943fa976c343537058647",
            "d40d5a872f7a4c8d930edd93170f1c7f",
            "0aebb875d6314297871762fd51e75a62"
          ]
        },
        "outputId": "a705f27c-69ae-4a0e-ae8c-0445b537b189"
      },
      "source": [
        "model = BertForSequenceClassification.from_pretrained(gv_model_nm, num_labels=8)\n",
        "model.cuda()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e5d334896a9e4048a2570b14a0df4fe8",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=625.0, style=ProgressStyle(description_…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4799a649d51e4bd69f96f99cb424d947",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, description='Downloading', max=1338740706.0, style=ProgressStyle(descr…"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "IN-6PpVwuzHO",
        "colab_type": "text"
      },
      "source": [
        "## 옵티마이저 및 에폭 설정"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fqixfflPijri",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "optimizer = AdamW(model.parameters(), lr = gv_lr, eps = gv_eps )\n",
        "epochs = gv_epoch\n",
        "total_steps = len(train_dataloader) * epochs\n",
        "scheduler = get_linear_schedule_with_warmup(optimizer, \n",
        "                                            num_warmup_steps = gv_num_warmup_steps,\n",
        "                                            num_training_steps = total_steps)"
      ],
      "execution_count": 61,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOLhwkBBvSp0",
        "colab_type": "text"
      },
      "source": [
        "# 모델 학습 - Traning Set"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kMdE_5xGvWT0",
        "colab_type": "text"
      },
      "source": [
        "## 함수 정의"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Ju-dBByNijmE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def flat_accuracy(preds, labels):\n",
        "    \n",
        "    pred_flat = np.argmax(preds, axis=1).flatten()\n",
        "    labels_flat = labels.flatten()\n",
        "\n",
        "    return np.sum(pred_flat == labels_flat) / len(labels_flat)"
      ],
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VinLTPp1vaET",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def format_time(elapsed):\n",
        "    elapsed_rounded = int(round((elapsed)))\n",
        "    return str(datetime.timedelta(seconds=elapsed_rounded))"
      ],
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l2LPvmVGvbsk",
        "colab_type": "text"
      },
      "source": [
        "## 학습 수행"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BPUzq7_A706w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "seed_val = gv_seed_val\n",
        "random.seed(seed_val)\n",
        "np.random.seed(seed_val)\n",
        "torch.manual_seed(seed_val)\n",
        "torch.cuda.manual_seed_all(seed_val)\n",
        "model.zero_grad()"
      ],
      "execution_count": 64,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PEFqLOoU8O-n",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bb66effa-6197-4a2b-d208-3b03b7ddef99"
      },
      "source": [
        "t0 = time.time()\n",
        "total_loss = 0\n",
        "model.train()"
      ],
      "execution_count": 65,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "BertForSequenceClassification(\n",
              "  (bert): BertModel(\n",
              "    (embeddings): BertEmbeddings(\n",
              "      (word_embeddings): Embedding(28996, 1024, padding_idx=0)\n",
              "      (position_embeddings): Embedding(512, 1024)\n",
              "      (token_type_embeddings): Embedding(2, 1024)\n",
              "      (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "      (dropout): Dropout(p=0.1, inplace=False)\n",
              "    )\n",
              "    (encoder): BertEncoder(\n",
              "      (layer): ModuleList(\n",
              "        (0): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (1): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (2): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (3): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (4): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (5): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (6): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (7): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (8): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (9): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (10): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (11): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (12): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (13): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (14): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (15): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (16): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (17): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (18): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (19): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (20): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (21): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (22): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "        (23): BertLayer(\n",
              "          (attention): BertAttention(\n",
              "            (self): BertSelfAttention(\n",
              "              (query): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (key): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (value): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "            (output): BertSelfOutput(\n",
              "              (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "              (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "              (dropout): Dropout(p=0.1, inplace=False)\n",
              "            )\n",
              "          )\n",
              "          (intermediate): BertIntermediate(\n",
              "            (dense): Linear(in_features=1024, out_features=4096, bias=True)\n",
              "          )\n",
              "          (output): BertOutput(\n",
              "            (dense): Linear(in_features=4096, out_features=1024, bias=True)\n",
              "            (LayerNorm): LayerNorm((1024,), eps=1e-12, elementwise_affine=True)\n",
              "            (dropout): Dropout(p=0.1, inplace=False)\n",
              "          )\n",
              "        )\n",
              "      )\n",
              "    )\n",
              "    (pooler): BertPooler(\n",
              "      (dense): Linear(in_features=1024, out_features=1024, bias=True)\n",
              "      (activation): Tanh()\n",
              "    )\n",
              "  )\n",
              "  (dropout): Dropout(p=0.1, inplace=False)\n",
              "  (classifier): Linear(in_features=1024, out_features=8, bias=True)\n",
              ")"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 65
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "inxRy3Vf8n1K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for step, batch in enumerate(train_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "    \n",
        "    outputs = model(b_input_ids, \n",
        "                    token_type_ids=None, \n",
        "                    attention_mask=b_input_mask, \n",
        "                    labels=b_labels)"
      ],
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JuuZMU4svgNP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        },
        "outputId": "749c709e-4325-43a6-a762-ad316d2a37fe"
      },
      "source": [
        "for epoch_i in range(0, epochs):\n",
        "    t0 = time.time()\n",
        "    total_loss = 0\n",
        "    model.train()\n",
        "\n",
        "    for step, batch in enumerate(train_dataloader):\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask, \n",
        "                        labels=b_labels)\n",
        "        \n",
        "        loss = outputs[0]\n",
        "        total_loss += loss.item()\n",
        "        loss.backward()\n",
        "        torch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        model.zero_grad()\n",
        "\n",
        "    avg_train_loss = total_loss / len(train_dataloader)           \n",
        "    t0 = time.time()\n",
        "    model.eval()\n",
        "    eval_loss, eval_accuracy = 0, 0\n",
        "    nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "    for batch in validation_dataloader:\n",
        "        batch = tuple(t.to(device) for t in batch)\n",
        "        b_input_ids, b_input_mask, b_labels = batch\n",
        "        with torch.no_grad():     \n",
        "            outputs = model(b_input_ids, \n",
        "                            token_type_ids=None, \n",
        "                            attention_mask=b_input_mask)\n",
        "            \n",
        "        logits = outputs[0]\n",
        "        logits = logits.detach().cpu().numpy()\n",
        "        label_ids = b_labels.to('cpu').numpy()        \n",
        "        tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "        eval_accuracy += tmp_eval_accuracy\n",
        "        nb_eval_steps += 1\n",
        "\n",
        "    print(\"  예상 Score : {0:.3f}\".format(eval_accuracy/nb_eval_steps))\n"
      ],
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  예상 Score : 0.632\n",
            "  예상 Score : 0.664\n",
            "  예상 Score : 0.666\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bavUeGWNExla",
        "colab_type": "text"
      },
      "source": [
        "# 평가 - Submit Set"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zxjZ3287IX4v",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 755
        },
        "outputId": "5187de6d-bbb3-4ffc-840a-1dce1153dc83"
      },
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "submit_preds =  []\n",
        "\n",
        "for step, batch in enumerate(submit_dataloader):\n",
        "\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():     \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "        \n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "    if step < 10:\n",
        "      print(step)\n",
        "      print(submit_preds[0:10])\n",
        "      print(logits.argmax(-1))    \n",
        "    submit_preds.extend(logits.argmax(-1))     \n",
        "    if step < 10:\n",
        "      print(submit_preds[0:10])   \n",
        "    \n",
        "print(\"예상 Score : {0:.3f}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0\n",
            "[]\n",
            "[4 7 0 4 0 5 4 5 4 4]\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "1\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "[5 4 4 4 3 7 6 7 4 4]\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "2\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "[4 4 7 5 3 0 0 0 0 0]\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "3\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "[0 4 6 4 4 5 4 4 7 4]\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "4\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "[4 4 7 7 4 7 6 7 4 4]\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "5\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "[4 4 4 4 4 4 7 3 5 4]\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "6\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "[7 4 5 4 4 5 4 7 0 3]\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "7\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "[7 4 4 3 4 0 0 0 3 0]\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "8\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "[4 7 4 3 4 3 3 4 4 4]\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "9\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "[4 4 4 4 0 5 4 4 4 4]\n",
            "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]\n",
            "예상 Score : 0.516\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0uy_e8hh_dR9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "415e4ef9-d32f-45d8-9089-245edcac79c4"
      },
      "source": [
        "print(np.argmax(logits))"
      ],
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "36\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BnAl3oDi_gsW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "103bd945-8dc3-4f46-b4bd-e33c2e31c394"
      },
      "source": [
        "submit_preds[0:10]"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[4, 7, 0, 4, 0, 5, 4, 5, 4, 4]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5rJaFyiT_7fz",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "eacb3c28-c883-4d02-9546-5f07e971aff5"
      },
      "source": [
        "logits.argmax(-1)"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([5, 4, 4, 5, 4, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OjytFtb3ayP",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        },
        "outputId": "6308f7e7-1ab7-460d-9974-0945ec79172b"
      },
      "source": [
        "print([labels_num[submit_pred] for submit_pred in submit_preds])"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "['neutral', 'surprise', 'anger', 'neutral', 'anger', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'sadness', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'joy', 'anger', 'anger', 'anger', 'anger', 'anger', 'anger', 'neutral', 'sadness', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'neutral', 'surprise', 'sadness', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'joy', 'non-neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'anger', 'joy', 'surprise', 'neutral', 'neutral', 'joy', 'neutral', 'anger', 'anger', 'anger', 'joy', 'anger', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'joy', 'neutral', 'non-neutral', 'joy', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'joy', 'surprise', 'neutral', 'non-neutral', 'neutral', 'joy', 'joy', 'joy', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'joy', 'surprise', 'non-neutral', 'joy', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'sadness', 'neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'neutral', 'joy', 'neutral', 'surprise', 'neutral', 'non-neutral', 'surprise', 'non-neutral', 'neutral', 'surprise', 'joy', 'neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'sadness', 'non-neutral', 'joy', 'joy', 'joy', 'neutral', 'surprise', 'anger', 'neutral', 'surprise', 'surprise', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'anger', 'neutral', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'sadness', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'non-neutral', 'joy', 'anger', 'neutral', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'non-neutral', 'surprise', 'joy', 'joy', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'sadness', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'non-neutral', 'joy', 'joy', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'joy', 'non-neutral', 'anger', 'joy', 'neutral', 'non-neutral', 'anger', 'surprise', 'anger', 'anger', 'non-neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'joy', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'anger', 'anger', 'anger', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'joy', 'joy', 'surprise', 'surprise', 'neutral', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'joy', 'anger', 'neutral', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'neutral', 'joy', 'surprise', 'anger', 'non-neutral', 'joy', 'neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'joy', 'non-neutral', 'joy', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'neutral', 'surprise', 'neutral', 'neutral', 'surprise', 'neutral', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'non-neutral', 'anger', 'non-neutral', 'non-neutral', 'surprise', 'joy', 'anger', 'anger', 'non-neutral', 'neutral', 'neutral', 'joy', 'neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'sadness', 'non-neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'joy', 'surprise', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'anger', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'surprise', 'neutral', 'joy', 'joy', 'neutral', 'joy', 'anger', 'neutral', 'non-neutral', 'neutral', 'joy', 'joy', 'joy', 'surprise', 'joy', 'joy', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'anger', 'neutral', 'non-neutral', 'non-neutral', 'anger', 'non-neutral', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'surprise', 'surprise', 'surprise', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'joy', 'neutral', 'surprise', 'neutral', 'surprise', 'non-neutral', 'non-neutral', 'surprise', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'neutral', 'anger', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'anger', 'non-neutral', 'non-neutral', 'non-neutral', 'anger', 'anger', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'anger', 'surprise', 'anger', 'surprise', 'neutral', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'joy', 'neutral', 'surprise', 'surprise', 'neutral', 'non-neutral', 'sadness', 'anger', 'neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'joy', 'joy', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'sadness', 'sadness', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'anger', 'joy', 'neutral', 'neutral', 'neutral', 'anger', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'anger', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'surprise', 'non-neutral', 'surprise', 'surprise', 'surprise', 'surprise', 'neutral', 'anger', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'surprise', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'joy', 'surprise', 'surprise', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'joy', 'neutral', 'joy', 'surprise', 'surprise', 'surprise', 'neutral', 'surprise', 'surprise', 'anger', 'non-neutral', 'neutral', 'anger', 'anger', 'neutral', 'neutral', 'neutral', 'surprise', 'joy', 'neutral', 'joy', 'non-neutral', 'non-neutral', 'joy', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'anger', 'non-neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'surprise', 'non-neutral', 'surprise', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'non-neutral', 'surprise', 'surprise', 'surprise', 'joy', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'surprise', 'neutral', 'anger', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'sadness', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'surprise', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'surprise', 'neutral', 'neutral', 'surprise', 'surprise', 'joy', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'sadness', 'surprise', 'joy', 'surprise', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'surprise', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'joy', 'joy', 'anger', 'anger', 'anger', 'non-neutral', 'neutral', 'anger', 'sadness', 'sadness', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'surprise', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'anger', 'neutral', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'joy', 'joy', 'neutral', 'surprise', 'joy', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'joy', 'anger', 'neutral', 'joy', 'neutral', 'surprise', 'neutral', 'surprise', 'joy', 'neutral', 'joy', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'non-neutral', 'sadness', 'surprise', 'joy', 'neutral', 'joy', 'joy', 'neutral', 'sadness', 'neutral', 'neutral', 'anger', 'surprise', 'anger', 'surprise', 'non-neutral', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'non-neutral', 'surprise', 'surprise', 'neutral', 'non-neutral', 'neutral', 'neutral', 'anger', 'non-neutral', 'neutral', 'joy', 'joy', 'non-neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'surprise', 'surprise', 'anger', 'neutral', 'surprise', 'surprise', 'neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'surprise', 'non-neutral', 'anger', 'non-neutral', 'surprise', 'joy', 'sadness', 'non-neutral', 'non-neutral', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'anger', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'surprise', 'sadness', 'non-neutral', 'surprise', 'surprise', 'non-neutral', 'anger', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'joy', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'anger', 'non-neutral', 'anger', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'joy', 'surprise', 'surprise', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'surprise', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'anger', 'neutral', 'neutral', 'neutral', 'surprise', 'joy', 'joy', 'non-neutral', 'joy', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'surprise', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'anger', 'neutral', 'neutral', 'joy', 'neutral', 'surprise', 'neutral', 'non-neutral', 'anger', 'surprise', 'non-neutral', 'neutral', 'surprise', 'surprise', 'joy', 'surprise', 'joy', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'anger', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'surprise', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'sadness', 'non-neutral', 'neutral', 'anger', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'joy', 'joy', 'sadness', 'neutral', 'neutral', 'joy', 'neutral', 'non-neutral', 'surprise', 'non-neutral', 'surprise', 'neutral', 'anger', 'anger', 'non-neutral', 'non-neutral', 'neutral', 'surprise', 'surprise', 'surprise', 'surprise', 'anger', 'surprise', 'joy', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'anger', 'anger', 'neutral', 'non-neutral', 'surprise', 'joy', 'joy', 'joy', 'joy', 'neutral', 'anger', 'non-neutral', 'joy', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'anger', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'sadness', 'non-neutral', 'joy', 'neutral', 'neutral', 'joy', 'joy', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'anger', 'sadness', 'sadness', 'joy', 'joy', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'non-neutral', 'anger', 'joy', 'surprise', 'non-neutral', 'anger', 'non-neutral', 'neutral', 'neutral', 'joy', 'joy', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'joy', 'anger', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'surprise', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'non-neutral', 'non-neutral', 'neutral', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'anger', 'non-neutral', 'joy', 'neutral', 'joy', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'sadness', 'non-neutral', 'surprise', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'sadness', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'anger', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'joy', 'non-neutral', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'non-neutral', 'anger', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'joy', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'joy', 'surprise', 'neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'joy', 'joy', 'neutral', 'anger', 'non-neutral', 'anger', 'surprise', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'non-neutral', 'anger', 'anger', 'anger', 'non-neutral', 'joy', 'anger', 'neutral', 'joy', 'joy', 'surprise', 'neutral', 'neutral', 'joy', 'neutral', 'joy', 'neutral', 'surprise', 'surprise', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'surprise', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'anger', 'neutral', 'neutral', 'surprise', 'joy', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'sadness', 'neutral', 'surprise', 'sadness', 'neutral', 'neutral', 'sadness', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'anger', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'joy', 'non-neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'anger', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'anger', 'neutral', 'non-neutral', 'joy', 'joy', 'anger', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'anger', 'surprise', 'non-neutral', 'surprise', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'neutral', 'non-neutral', 'neutral', 'surprise', 'surprise', 'surprise', 'non-neutral', 'neutral', 'surprise', 'sadness', 'neutral', 'non-neutral', 'non-neutral', 'surprise', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'neutral', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'joy', 'joy', 'surprise', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'anger', 'surprise', 'anger', 'anger', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'anger', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'anger', 'surprise', 'anger', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'joy', 'joy', 'surprise', 'neutral', 'neutral', 'joy', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'joy', 'surprise', 'surprise', 'neutral', 'neutral', 'anger', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'sadness', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'surprise', 'surprise', 'anger', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'surprise', 'non-neutral', 'joy', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'non-neutral', 'surprise', 'joy', 'joy', 'neutral', 'joy', 'neutral', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'joy', 'neutral', 'joy', 'neutral', 'joy', 'neutral', 'non-neutral', 'neutral', 'anger', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'sadness', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'anger', 'non-neutral', 'neutral', 'non-neutral', 'joy', 'joy', 'non-neutral', 'anger', 'neutral', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'joy', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'sadness', 'joy', 'surprise', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'neutral', 'surprise', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'joy', 'surprise', 'non-neutral', 'surprise', 'neutral', 'neutral', 'non-neutral', 'joy', 'surprise', 'non-neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'surprise', 'non-neutral', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'neutral', 'surprise', 'non-neutral', 'non-neutral', 'surprise', 'sadness', 'joy', 'non-neutral', 'neutral', 'non-neutral', 'sadness', 'joy', 'non-neutral', 'neutral', 'joy', 'neutral', 'joy', 'joy', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'joy', 'non-neutral', 'neutral', 'sadness', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'non-neutral', 'sadness', 'surprise', 'non-neutral', 'non-neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'joy', 'non-neutral', 'joy', 'neutral', 'joy', 'joy', 'neutral', 'neutral', 'joy', 'non-neutral', 'anger', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'surprise', 'anger', 'anger', 'sadness', 'neutral', 'non-neutral', 'joy', 'joy', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'sadness', 'surprise', 'non-neutral', 'joy', 'surprise', 'non-neutral', 'non-neutral', 'joy', 'joy', 'joy', 'surprise', 'neutral', 'non-neutral', 'neutral', 'anger', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'anger', 'non-neutral', 'anger', 'anger', 'non-neutral', 'neutral', 'anger', 'surprise', 'neutral', 'neutral', 'neutral', 'anger', 'anger', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'surprise', 'sadness', 'neutral', 'neutral', 'anger', 'anger', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'neutral', 'joy', 'neutral', 'anger', 'non-neutral', 'surprise', 'anger', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'surprise', 'anger', 'neutral', 'anger', 'anger', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'anger', 'sadness', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'surprise', 'joy', 'surprise', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'non-neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'surprise', 'joy', 'non-neutral', 'joy', 'neutral', 'surprise', 'neutral', 'joy', 'neutral', 'joy', 'sadness', 'non-neutral', 'surprise', 'non-neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'anger', 'non-neutral', 'non-neutral', 'joy', 'joy', 'non-neutral', 'joy', 'non-neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'non-neutral', 'surprise', 'non-neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'non-neutral', 'joy', 'surprise', 'non-neutral', 'joy', 'neutral', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'anger', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'joy', 'neutral', 'sadness', 'surprise', 'surprise', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'surprise', 'surprise', 'joy', 'non-neutral', 'joy', 'joy', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'anger', 'anger', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'joy', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'joy', 'surprise', 'surprise', 'neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'joy', 'non-neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'anger', 'surprise', 'non-neutral', 'surprise', 'neutral', 'anger', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'joy', 'joy', 'anger', 'non-neutral', 'joy', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'anger', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'surprise', 'surprise', 'non-neutral', 'non-neutral', 'joy', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'non-neutral', 'surprise', 'surprise', 'surprise', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'surprise', 'anger', 'anger', 'anger', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'surprise', 'surprise', 'neutral', 'neutral', 'joy', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'joy', 'neutral', 'surprise', 'neutral', 'surprise', 'neutral', 'anger', 'anger', 'anger', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'sadness', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'anger', 'anger', 'non-neutral', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'surprise', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'joy', 'non-neutral', 'joy', 'neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'non-neutral', 'non-neutral', 'non-neutral', 'surprise', 'neutral', 'surprise', 'joy', 'non-neutral', 'neutral', 'joy', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'anger', 'anger', 'non-neutral', 'anger', 'anger', 'neutral', 'anger', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'surprise', 'surprise', 'non-neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'joy', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'non-neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'joy', 'joy', 'surprise', 'neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'surprise', 'neutral', 'non-neutral', 'anger', 'neutral', 'surprise', 'surprise', 'non-neutral', 'neutral', 'non-neutral', 'surprise', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'joy', 'non-neutral', 'sadness', 'neutral', 'non-neutral', 'neutral', 'non-neutral', 'surprise', 'surprise', 'surprise', 'non-neutral', 'neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'non-neutral', 'anger', 'neutral', 'neutral', 'non-neutral', 'joy', 'joy', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'neutral', 'surprise', 'neutral', 'sadness', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'neutral', 'non-neutral', 'joy', 'neutral', 'neutral', 'surprise', 'neutral', 'neutral', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'joy', 'neutral', 'neutral', 'neutral', 'anger', 'surprise', 'surprise', 'surprise', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'non-neutral', 'non-neutral', 'non-neutral', 'neutral', 'neutral', 'non-neutral', 'neutral', 'joy']\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cQHbcwmLyyq6",
        "colab_type": "text"
      },
      "source": [
        "# 평가 - Test Set "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wh9Tg6I7zF6O",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "4b9ee2e4-3adf-4a91-9131-310d42223e4c"
      },
      "source": [
        "t0 = time.time()\n",
        "model.eval()\n",
        "eval_loss, eval_accuracy = 0, 0\n",
        "nb_eval_steps, nb_eval_examples = 0, 0\n",
        "\n",
        "for step, batch in enumerate(test_dataloader):\n",
        "    batch = tuple(t.to(device) for t in batch)\n",
        "    b_input_ids, b_input_mask, b_labels = batch\n",
        "\n",
        "    with torch.no_grad():     \n",
        "        outputs = model(b_input_ids, \n",
        "                        token_type_ids=None, \n",
        "                        attention_mask=b_input_mask)\n",
        "        \n",
        "    logits = outputs[0]\n",
        "    logits = logits.detach().cpu().numpy()\n",
        "    label_ids = b_labels.to('cpu').numpy()\n",
        "    tmp_eval_accuracy = flat_accuracy(logits, label_ids)\n",
        "    eval_accuracy += tmp_eval_accuracy\n",
        "    nb_eval_steps += 1\n",
        "\n",
        "print(\"예상 Score : {0:.3f}\".format(eval_accuracy/nb_eval_steps))"
      ],
      "execution_count": 73,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "예상 Score : 0.627\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "87MMN0IHw_YG",
        "colab_type": "text"
      },
      "source": [
        "# 캐글용 csv 생성"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z5RG8gN-o5f4",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "submit_pred_labels = [labels_num[submit_pred] for submit_pred in submit_preds]"
      ],
      "execution_count": 74,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VVdL_WXhbtuV",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 17
        },
        "outputId": "f762d611-d406-4a7d-b188-5fa8aee4d330"
      },
      "source": [
        "submission_dic = {\"id\":list(range(len(submit_pred_labels))), \"Predicted\":submit_pred_labels} \n",
        "submission_df = pd.DataFrame(submission_dic) \n",
        "submission_df.to_csv(\"DFC615E 20061X X.csv\", index=False)\n",
        "files.download(\"DFC615E 20061X X.csv\")"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "\n",
              "    async function download(id, filename, size) {\n",
              "      if (!google.colab.kernel.accessAllowed) {\n",
              "        return;\n",
              "      }\n",
              "      const div = document.createElement('div');\n",
              "      const label = document.createElement('label');\n",
              "      label.textContent = `Downloading \"${filename}\": `;\n",
              "      div.appendChild(label);\n",
              "      const progress = document.createElement('progress');\n",
              "      progress.max = size;\n",
              "      div.appendChild(progress);\n",
              "      document.body.appendChild(div);\n",
              "\n",
              "      const buffers = [];\n",
              "      let downloaded = 0;\n",
              "\n",
              "      const channel = await google.colab.kernel.comms.open(id);\n",
              "      // Send a message to notify the kernel that we're ready.\n",
              "      channel.send({})\n",
              "\n",
              "      for await (const message of channel.messages) {\n",
              "        // Send a message to notify the kernel that we're ready.\n",
              "        channel.send({})\n",
              "        if (message.buffers) {\n",
              "          for (const buffer of message.buffers) {\n",
              "            buffers.push(buffer);\n",
              "            downloaded += buffer.byteLength;\n",
              "            progress.value = downloaded;\n",
              "          }\n",
              "        }\n",
              "      }\n",
              "      const blob = new Blob(buffers, {type: 'application/binary'});\n",
              "      const a = document.createElement('a');\n",
              "      a.href = window.URL.createObjectURL(blob);\n",
              "      a.download = filename;\n",
              "      div.appendChild(a);\n",
              "      a.click();\n",
              "      div.remove();\n",
              "    }\n",
              "  "
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "application/javascript": [
              "download(\"download_98f1ac63-44ac-4e76-bb8f-c7f3e0a3c15d\", \"DFC615E 20061X X.csv\", 42350)"
            ],
            "text/plain": [
              "<IPython.core.display.Javascript object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    }
  ]
}